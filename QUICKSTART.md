# ğŸš€ Quick Start Guide

## Installation & Setup (5 minutes)

### Option 1: Automated Setup (Recommended)

```bash
# Run the setup script
python setup.py

# This will:
# âœ… Check Python version
# âœ… Install all dependencies
# âœ… Download NLTK data
# âœ… Verify dataset files
```

### Option 2: Manual Setup

```bash
# 1. Create virtual environment (optional but recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 2. Install dependencies
pip install -r requirements.txt

# 3. Download NLTK data
python -m nltk.downloader stopwords punkt averaged_perceptron_tagger
```

---

## ğŸ¯ Launch the Dashboard (1 minute)

```bash
streamlit run streamlit_dashboard.py
```

âœ… **Dashboard opens at:** http://localhost:8501

### Dashboard Navigation

| Section | What You'll See |
|---------|-----------------|
| ğŸ  Home | Quick stats & overview |
| ğŸ“Š Dataset Overview | Columns, types, structure |
| ğŸ” Data Quality | Missing values, duplicates |
| ğŸ“ˆ Statistical Analysis | Distributions, statistics |
| ğŸ¥ Medical Domain | Disease/intent categories |
| ğŸ“ NLP Analysis | Text patterns, keywords |
| ğŸ¯ Key Findings | Overall assessment |
| ğŸ”§ Preprocessing | Data pipeline guide |
| ğŸ¤– Model Recommendations | Best practices |

---

## ğŸ““ View Detailed Analysis (Optional)

```bash
# Option 1: Jupyter Notebook
jupyter notebook Professional_EDA_Report.ipynb

# Option 2: JupyterLab
jupyter lab Professional_EDA_Report.ipynb

# Option 3: Export to HTML
jupyter nbconvert --to html Professional_EDA_Report.ipynb
```

---

## ğŸ“Š What's in the Dashboard?

### Data Quality Metrics
- âœ… Missing values analysis
- âœ… Duplicate detection
- âœ… Data completeness score
- âœ… Overall quality assessment

### Statistical Insights
- ğŸ“ˆ Distribution analysis
- ğŸ“Š Summary statistics
- ğŸ“‰ Trend visualization
- ğŸ” Outlier detection

### Medical Domain Analysis
- ğŸ¥ Disease/Intent categories
- âš–ï¸ Category balance
- ğŸ“Š Domain coverage
- ğŸ¯ Imbalance assessment

### NLP Insights
- ğŸ“ Question/Answer analysis
- ğŸ“š Text length patterns
- ğŸ”¤ Keyword extraction
- ğŸ“– Vocabulary diversity

### Model Readiness
- âœ… Training readiness score
- ğŸ“‹ Preprocessing checklist
- ğŸ¤– Model recommendations
- ğŸš€ Deployment guidelines

---

## ğŸ”§ Common Tasks

### Export Data to CSV
```python
import pandas as pd

df = pd.read_csv('ai-medical-chatbot.csv')

# Clean data
df = df.drop_duplicates()
df = df.dropna()

# Save
df.to_csv('ai-medical-chatbot-cleaned.csv', index=False)
```

### Analyze Specific Column
```python
import pandas as pd

df = pd.read_csv('ai-medical-chatbot.csv')

# Get column info
print(f"Unique values: {df['column_name'].nunique()}")
print(f"Most common: {df['column_name'].value_counts().head()}")
print(f"Missing: {df['column_name'].isna().sum()}")
```

### Generate Preprocessing Code
```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Load data
df = pd.read_csv('ai-medical-chatbot.csv')

# Train/test split (80/20)
train, test = train_test_split(df, test_size=0.2, random_state=42)

# Stratified split by category
train, test = train_test_split(
    df, test_size=0.2, 
    stratify=df['category'],  # Balance categories
    random_state=42
)

# Scale numeric features
scaler = StandardScaler()
scaled_features = scaler.fit_transform(train.select_dtypes(include=['number']))
```

---

## ğŸ“š Key Statistics to Check

After launching the dashboard, verify:

| Metric | Expected Value | Status |
|--------|---|---|
| Data Completeness | > 95% | âœ… |
| Duplicate Records | < 1% | âœ… |
| Missing Values | < 5% | âœ… |
| Text Columns | â‰¥ 2 | âœ… |
| Unique Categories | > 10 | âœ… |

---

## ğŸ› Troubleshooting

### Dashboard won't start?
```bash
# Clear Streamlit cache
streamlit cache clear

# Try different port
streamlit run streamlit_dashboard.py --server.port 8502
```

### Data not loading?
```python
# Check if file exists and is accessible
import os
print(os.path.exists('ai-medical-chatbot.csv'))
print(os.path.getsize('ai-medical-chatbot.csv') / 1024**2)  # Size in MB
```

### Dependencies not installing?
```bash
# Upgrade pip
python -m pip install --upgrade pip

# Try installing individually
pip install pandas numpy matplotlib seaborn streamlit
```

---

## ğŸ“– Documentation

- **README.md** - Full project documentation
- **requirements.txt** - All dependencies
- **Professional_EDA_Report.ipynb** - Detailed analysis notebook
- **streamlit_dashboard.py** - Dashboard source code

---

## ğŸš€ Next Steps

1. âœ… **Explore the Dashboard** - Get familiar with your data
2. âœ… **Review Key Findings** - Check data quality metrics
3. âœ… **Run Preprocessing** - Clean and prepare data
4. âœ… **Train Models** - Follow model recommendations
5. âœ… **Deploy Chatbot** - Follow deployment guide

---

## ğŸ’¡ Tips

- **First Time?** â†’ Start with the Home page
- **Need Stats?** â†’ Check Dataset Overview
- **Data Issues?** â†’ Go to Data Quality section
- **Training Models?** â†’ See Model Recommendations
- **Ready for Deployment?** â†’ Check Key Findings

---

## â±ï¸ Time Estimates

| Task | Time |
|------|------|
| Setup | 5 min |
| Dashboard Exploration | 10-15 min |
| Full Dashboard Review | 30-45 min |
| Notebook Analysis | 1-2 hours |
| Data Preprocessing | 2-4 hours |
| Model Training | 4-8 hours |

---

## ğŸ“ Need Help?

1. Check README.md for detailed documentation
2. Review the Jupyter notebook for examples
3. Check Streamlit documentation: https://docs.streamlit.io
4. NLTK documentation: https://www.nltk.org

---

**Ready? Let's go! ğŸ‰**

```bash
streamlit run streamlit_dashboard.py
```

Your dashboard awaits at **http://localhost:8501** ğŸš€
